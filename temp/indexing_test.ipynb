{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05366ca4-cc71-4e9f-888d-f6ab74b8a231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:37:36.800919Z",
     "iopub.status.busy": "2024-05-24T09:37:36.800479Z",
     "iopub.status.idle": "2024-05-24T09:37:36.804104Z",
     "shell.execute_reply": "2024-05-24T09:37:36.803499Z",
     "shell.execute_reply.started": "2024-05-24T09:37:36.800888Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformers==4.41.1\n",
    "#!pip install datasets==2.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0103d6ec-34de-4fa3-ba7a-8765dbb99827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:40:31.501207Z",
     "iopub.status.busy": "2024-05-24T09:40:31.500785Z",
     "iopub.status.idle": "2024-05-24T09:40:31.505530Z",
     "shell.execute_reply": "2024-05-24T09:40:31.504909Z",
     "shell.execute_reply.started": "2024-05-24T09:40:31.501175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from transformers.trainer_pt_utils import IterableDatasetShard\n",
    "from datasets import Dataset, DatasetDict,IterableDatasetDict\n",
    "from datasets import load_dataset\n",
    "import pyarrow.parquet as pq\n",
    "from abc import *\n",
    "from typing import Union, Dict, Set, List, Callable, Tuple, Any\n",
    "from torch.utils.data import IterableDataset, Dataset, DataLoader\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4c1d3-ca1e-462b-84c8-3bd41a7ebbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a3d026-f2a4-400f-bf07-07a662bdcf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:38:24.260307Z",
     "iopub.status.busy": "2024-05-24T09:38:24.259672Z",
     "iopub.status.idle": "2024-05-24T09:38:24.273515Z",
     "shell.execute_reply": "2024-05-24T09:38:24.272881Z",
     "shell.execute_reply.started": "2024-05-24T09:38:24.260268Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractPreprocessor(metaclass=ABCMeta):\n",
    "    def __init__(self, args, **kwargs):\n",
    "        self.args = args\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def clean_cache_dir(cls, cache_dir):\n",
    "        shutil.rmtree(cache_dir)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file_path:Union[str, List], split:str=None, stream:bool=True, keep_in_memory:bool=True, is_cache:bool=True, cache_dir:str='./.cache') -> IterableDataset:\n",
    "        \n",
    "        _, before_mem_usage_gb, before_mem_avail_gb = cls.get_ram_usage_percent()\n",
    "\n",
    "        if isinstance(file_path, List):\n",
    "            dataset = load_dataset(\"parquet\", \n",
    "                                   data_files=file_path, \n",
    "                                   split=split, \n",
    "                                   keep_in_memory=keep_in_memory, \n",
    "                                   streaming=stream,\n",
    "                                   cache_dir=cache_dir)\n",
    "\n",
    "        elif isinstance(file_path, str):\n",
    "            if os.path.isfile(file_path):\n",
    "                dataset = load_dataset(\"parquet\", \n",
    "                                       data_files=file_path, \n",
    "                                       split=split, \n",
    "                                       keep_in_memory=keep_in_memory, \n",
    "                                       streaming=stream,\n",
    "                                       cache_dir=cache_dir)\n",
    "            \n",
    "            elif os.path.isdir(file_path):\n",
    "                dataset = load_dataset(file_path, \n",
    "                                       streaming=stream,\n",
    "                                       cache_dir=cache_dir)\n",
    "            else:\n",
    "                raise FileNotFoundError(f'{file_path} should be dir_path | file_path')\n",
    "        else:\n",
    "            raise TypeError(f'file_path should be in type str | List')\n",
    "        \n",
    "        if split is None:\n",
    "            dataset = dataset['train']\n",
    "        \n",
    "        mem_usage_percent, mem_usage_gb, mem_avail_gb = cls.get_ram_usage_percent()\n",
    "\n",
    "        ## 추후 Logger로 바꾸기 ## \n",
    "        print(f'mem usage percent: {mem_usage_percent}%')\n",
    "        print(f'before_mem_avail_gb: {before_mem_avail_gb} gb')\n",
    "        print(f'mem usage gb: {mem_usage_gb} gb')\n",
    "        print(f'mem avail gb: {mem_avail_gb} gb')\n",
    "\n",
    "        print(f'only file memory usage: {mem_usage_gb - before_mem_usage_gb}' )\n",
    "\n",
    "\n",
    "        if not is_cache:\n",
    "            cls.clean_cache()\n",
    "\n",
    "        return dataset\n",
    "            \n",
    "    @classmethod\n",
    "    def clean_cache(cls, dataset:Union[IterableDataset, Dataset]):\n",
    "        dataset.cleanup_cache_files()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_ram_usage_percent():\n",
    "        \"\"\"Returns the current system-wide RAM usage as a percentage.\"\"\"\n",
    "\n",
    "        mem = psutil.virtual_memory()\n",
    "\n",
    "        return mem.percent, mem.used / (1024 ** 3), mem.available / (1024 ** 3)        \n",
    "    \n",
    "    @staticmethod\n",
    "    def select_columns(dataset: Union[IterableDataset, Dataset, IterableDatasetDict], column_names:list=[]):\n",
    "        if isinstance(dataset, IterableDataset) or isinstance(dataset, IterableDatasetDict):\n",
    "            if isinstance(column_names, str):\n",
    "                 column_names = column_names.split(',')\n",
    "            elif isinstance(column_names, list):\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                raise TypeError('column_names should be list or string type')\n",
    "            \n",
    "            dataset = dataset.select_columns(column_names)\n",
    "                \n",
    "        elif isinstance(dataset, Dataset):\n",
    "            dataset = dataset['train'].select_columns([column_names])\n",
    "            \n",
    "        else:\n",
    "            raise TypeError(f'dataset should be IterableDataset | Dataset')\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    \n",
    "    @abstractmethod\n",
    "    def preprocess(self, item):\n",
    "        f\"\"\"code for apply to map function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99c01937-162a-44fb-9a78-2d1f13cea1ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:38:30.468307Z",
     "iopub.status.busy": "2024-05-24T09:38:30.467863Z",
     "iopub.status.idle": "2024-05-24T09:38:30.476660Z",
     "shell.execute_reply": "2024-05-24T09:38:30.475982Z",
     "shell.execute_reply.started": "2024-05-24T09:38:30.468265Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StreamPreprocessor(AbstractPreprocessor):\n",
    "    def __init__(self, args, **kwargs):        \n",
    "        super().__init__(args)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file_path:Union[str, List], split:str=None, keep_in_memory:bool=True, is_cache:bool=True) -> IterableDataset:        \n",
    "        stream = True\n",
    "        dataset = super(StreamPreprocessor, cls).load(\n",
    "                file_path=file_path, \n",
    "                split=split, \n",
    "                stream=stream, \n",
    "                keep_in_memory=keep_in_memory,\n",
    "                is_cache=is_cache\n",
    "        )\n",
    "        return dataset\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def shuffle(cls, dataset:IterableDataset, seed:int=777, buffer_size:int=1000) -> IterableDataset:\n",
    "        return dataset.shuffle(seed=seed, buffer_size=buffer_size)\n",
    "\n",
    "    @abstractmethod\n",
    "    def preprocess(self, item):\n",
    "        \"\"\" Implement preprocessing logic\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def apply_maps(cls, dataset:Dataset, functions_list: List[Tuple[Callable[..., Any], bool]]) -> Dataset:\n",
    "        \"\"\" instance method for apply list of functions\"\"\"\n",
    "        for func, with_indices in functions_list:\n",
    "            dataset = cls.apply_map(dataset=dataset, func=func, with_indices=with_indices)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    @classmethod\n",
    "    def apply_map(cls, dataset: Dataset, func:Callable, with_indices: bool = True) -> Dataset:\n",
    "        \"\"\" instance method for apply only one function\"\"\"\n",
    "        dataset = dataset.map(func, with_indices=with_indices)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "559c98ab-4d19-49ba-b48b-f7bdd7179b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:42:54.230816Z",
     "iopub.status.busy": "2024-05-24T09:42:54.230393Z",
     "iopub.status.idle": "2024-05-24T09:42:54.233894Z",
     "shell.execute_reply": "2024-05-24T09:42:54.233277Z",
     "shell.execute_reply.started": "2024-05-24T09:42:54.230784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#embedding_root_path = \"/data/temp/one_model_2024-05-11/one_model_v3_result_adot_20240511_0_emb.parquet.gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b41f84-9561-4d8c-93e1-be91b033b5a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:43:08.537271Z",
     "iopub.status.busy": "2024-05-24T09:43:08.536841Z",
     "iopub.status.idle": "2024-05-24T09:43:08.540526Z",
     "shell.execute_reply": "2024-05-24T09:43:08.539909Z",
     "shell.execute_reply.started": "2024-05-24T09:43:08.537237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_path = \"/home/x1112436/onemodel/data/opensearch/indexing_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e08af39-51bc-49da-b5cf-16c0cd060bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T09:43:13.070204Z",
     "iopub.status.busy": "2024-05-24T09:43:13.069763Z",
     "iopub.status.idle": "2024-05-24T09:43:13.402074Z",
     "shell.execute_reply": "2024-05-24T09:43:13.401407Z",
     "shell.execute_reply.started": "2024-05-24T09:43:13.070171Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem usage percent: 13.0%\n",
      "before_mem_avail_gb: 438.0115394592285 gb\n",
      "mem usage gb: 59.92805099487305 gb\n",
      "mem avail gb: 438.00575256347656 gb\n",
      "only file memory usage: 0.006267547607421875\n"
     ]
    }
   ],
   "source": [
    "dataset = StreamPreprocessor.load(file_path=local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5385513-92c8-45cf-a060-bce9b9f73e5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:57:37.310812Z",
     "iopub.status.busy": "2024-05-24T12:57:37.310320Z",
     "iopub.status.idle": "2024-05-24T12:57:37.317268Z",
     "shell.execute_reply": "2024-05-24T12:57:37.316526Z",
     "shell.execute_reply.started": "2024-05-24T12:57:37.310779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_input(item, index_name:str):\n",
    "    user_vector =  [float(x) for x in item['user_vector']]\n",
    "    svc_mgmt_num = str(item.get(\"svc_mgmt_num\", \"temp\"))  \n",
    "    luna_id = item.get(\"luna_id\", \"temp\")\n",
    "    if luna_id is None:\n",
    "        is_adot = False\n",
    "    else:\n",
    "        is_adot= True\n",
    "                               \n",
    "    mno_profile = item.get(\"mno_profile\", \"\")\n",
    "    adot_profile = item.get(\"adot_profile\", \"\")\n",
    "    behavior_profiles = item.get(\"behavior_profiles\", \"\")\n",
    "                               \n",
    "    doc = {\n",
    "        \"_index\": index_name,\n",
    "        \"_id\": svc_mgmt_num,\n",
    "        \"svc_mgmt_num\": svc_mgmt_num,\n",
    "        \"luna_id\": item.get(\"luna_id\", \"temp\"),\n",
    "        \"user_embedding\":user_vector,\n",
    "        \"mno_profile\": mno_profile,\n",
    "        \"adot_profile\": adot_profile,\n",
    "        \"behavior_profile\": behavior_profiles,\n",
    "        \"is_adot\": is_adot\n",
    "    }\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b89575d-feaf-444c-8964-f69cca56b411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:57:41.338225Z",
     "iopub.status.busy": "2024-05-24T12:57:41.337784Z",
     "iopub.status.idle": "2024-05-24T12:57:41.342026Z",
     "shell.execute_reply": "2024-05-24T12:57:41.341389Z",
     "shell.execute_reply.started": "2024-05-24T12:57:41.338193Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d9cbf5a-50ce-4b70-873d-261b72957b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:57:56.092369Z",
     "iopub.status.busy": "2024-05-24T12:57:56.091929Z",
     "iopub.status.idle": "2024-05-24T12:57:59.373604Z",
     "shell.execute_reply": "2024-05-24T12:57:59.372605Z",
     "shell.execute_reply.started": "2024-05-24T12:57:56.092336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_input() missing 1 required positional argument: 'index_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/datasets/iterable_dataset.py:1389\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, example \u001b[38;5;129;01min\u001b[39;00m ex_iterable:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[1;32m   1391\u001b[0m         \u001b[38;5;66;03m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m         \u001b[38;5;66;03m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m         example \u001b[38;5;241m=\u001b[39m _apply_feature_types_on_example(\n\u001b[1;32m   1394\u001b[0m             example, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, token_per_repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_per_repo_id\n\u001b[1;32m   1395\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/datasets/iterable_dataset.py:679\u001b[0m, in \u001b[0;36mMappedExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m ArrowExamplesIterable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_arrow, {})\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/datasets/iterable_dataset.py:752\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m     function_args\u001b[38;5;241m.\u001b[39mappend(current_idx)\n\u001b[1;32m    751\u001b[0m transformed_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(example)  \u001b[38;5;66;03m# this will be updated with the function output\u001b[39;00m\n\u001b[0;32m--> 752\u001b[0m transformed_example\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# then we remove the unwanted columns\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_columns:\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_input() missing 1 required positional argument: 'index_name'"
     ]
    }
   ],
   "source": [
    "next(iter(dataset))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602df1dc-675d-403f-b50e-b2ab2b2938cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
